---
title: "FinalProject_Report"
author: "Daniil Finkel, Omar Boffil, Albert Ferguson"
date: "August 2, 2020"
output:
  html_document:
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---

#### Team DOT:
- Daniilf2 - Daniil Finkel
- Oboffil2 - Omar Boffil
- Albertf2 - Albert Ferguson

# STAT 420: Final Project
## Predicting UPDRS (Unified Parkinson Disease Rating Scale) from Biomedical Voice Measurements of Individuals with Early Stage Parkinson’s Disease

<br>

### Introduction

Telehealth is a growing field. Remote medical examinations offer several benefits over conventional on-site methods:

- Secure and confidential: patients do not need to be seen at a specialists office
- Convenience: patients can attend appointments from comfort of their own home
- Increased access: patients are no longer restricted to geographically local physicians
- Reduced cancellation: patients more consistently attend, more closely monitored
- Many others

*Telemonitoring* is one form of telehealth in which information technology is used to monitor patients at a distance. The feasibility of such automated approaches calls for robust diagnoses to justify widespread adoption. This project aims to contribute to that goal. 

Parkinson’s disease is a neurodegenerative disease characterized by stiffness and shakiness in motor functions of affected individuals. The disease tends to become more severe over time.

A research collaboration between the University of Oxford, 10 medical centers in the US, and Intel Corporation organized a 6-month trial, recording a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease. The effort produced a dataset with the following characteristics:

- 5875 observations
- 22 attributes:
  - subject# - Integer that uniquely identifies each subject
  - age - Subject age
  - sex - Subject gender '0' - male, '1' - female
  - test_time - Time since recruitment into the trial. The integer part is the
  - number of days since recruitment.
  - motor_UPDRS - Clinician's motor UPDRS score, linearly interpolated
  - total_UPDRS - Clinician's total UPDRS score, linearly interpolated
  - Jitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP
  - - Several measures of variation in fundamental frequency
  - Shimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA
  - - Several measures of variation in amplitude
  - NHR,HNR - Two measures of ratio of noise to tonal components in the voice
  - RPDE - A nonlinear dynamical complexity measure
  - DFA - Signal fractal scaling exponent
  - PPE - A nonlinear measure of fundamental frequency variation

The dataset and a description of the aims of it’s collection are provided here: https://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring

A key attribute in the above set is `total_UPDRS`. The Unified Parkinson's Disease Rating Scale (UPDRS) is used to measure the degree of Parkinson’s in an individual - a higher score indicating a more severe case.

This project aims to develop a model to predict `total_UPDRS` using the remaining attributes, effectively developing a model to predict the degree to which an individual is affected by Parkinson’s disease.

<br>

**Let's take a closer look and do a little bit of pre-processing on the data:**

<br>

### Methods

#### Exploratory Phase

Examining the dataset revealed it was already very clean. There were no empty values or obvious typos that needed to be fixed. However, looking over the column names and underlying data revealed some modifications needed to be made before modeling. 
```{r, message = FALSE}
library(readr)
parkins = read_csv("parkinsons_updrs.csv")
```

<br>


The "\`subject#\`" column is a unique identifier for each individual. Because our aim is to develop a model that is generally applicable, and not fit to specific individuals of this 42-person study, we will remove it.

```{r}
parkins = subset(parkins, select = -c(`subject#`))
```
```{r, echo=FALSE}
parkins_orig = parkins
```
<br>

##### Variable Examination

Let's take a quick look at the distributions of all of the predictors in the dataset:

```{r message=FALSE, warning=FALSE}
library(purrr)
library(tidyr)
library(ggplot2)

parkins %>%
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram()
```


We see right away that the individuals range in age from about 35-90, with the majority of them falling between 55-80 years old.

<br>

There are also many columns with `Jitter` or `Shimmer` in their names, so we suspect there will be some colinearity among them. In addition, since the `motor_UPDRS` score is factored into the `total_UPDRS` score, they are expected to be highly correlated with each other. Figures 1-4 show scatterplots of all the columns against our response, `total_UPDRS`, as well as with columns where we suspect collinearity. Predictor columns highly correlated with other predictors are colinear and should likely be removed, but predictor columns higly correlated with our response variable are likely to improve the model.
```{r, eval=FALSE}
library(GGally)
ggpairs(columns = c(5, 4, 1, 2, 3), data=parkins)
ggpairs(columns = c(5, 17, 18, 19, 20, 21), data=parkins)
ggpairs(columns = c(5, 6, 7, 8, 9, 10), data=parkins)
ggpairs(columns = c(5, 11, 12, 13, 14, 15, 16), data=parkins)
```

Another method of measuring colinearity is through the variance inflation factors (VIF) of the individual predictor columns with each other, where values larger than `10` imply a signficant collinearity. 
```{r, eval=FALSE}
library(faraway)
faraway::vif(parkins)
```

An interesting property of VIF is that if two columns are colinear, their VIF values will be very large. However, if one of those columns is removed and the VIF is recalculated, the leftover column's VIF value will drop significantly if there are no other columns colinear with it. With this, we can take an iterative approach and repeatedly remove the column with the largest VIF until the resulting columns all have values less than `10` or `5`.
```{r}
# Drop columns that have a vif > 5, starting with highest first
fix_vif = function (data) {
  newData = data
  max_vif = max(faraway::vif(newData))
  while (max_vif > 5) {
    #print(summary(lm(total_UPDRS ~ ., data = newData))$adj)
    newData = subset(newData, select = c(setdiff(names(newData), names(which.max(faraway::vif(newData))))))
    max_vif = max(faraway::vif(newData))
  }
  newData
}
```

Evaluating our measures of colinearity, `motor_UPDRS` was found to be highly colinear with `total_UPDRS`, as expected. It makes sense that knowledge of a subject's `motor_UPDRS` score would be incredibly informative for calculating their total score, but a predictive model likely wouldn't be needed if that information was already available, so we chose to reomve it from our model building process.
```{r}
parkins = subset(parkins, select = -c(motor_UPDRS))
```

Evaluating the other columns did not show any strong linear correlations with `total_UPDRS`, unfortunately, so there was no early indication that an additive model would be enough. On the other hand, there also were no obvious polynomial relationships, so we felt confident we would not need to apply any polynomial transformations. Interactions were still a strong possibility that couldn't be ignored, especially with `sex` being a factor variable.

#### Model Building Phase

To get a general idea of how effective the predictors would be, we used all the rows and all the columns to train fully additive and interaction models. 
```{r}
additive_fit = lm(total_UPDRS ~ . , data = parkins)
interaction_fit = lm(total_UPDRS ~ (.)^2 , data = parkins)
```
- The fully additive model created a poorly fit model with an adjusted R^2 of `0.1739`. 
- The interaction model gave a slight improvment, with an adjusted R^2 of `0.3199`.




#### Helper functions:

We first create a suite of helper functions to more easily evaluate our models.

```{r, message = FALSE, warning = FALSE}

library(lmtest)

calc_rmse = function(model, tst_data){
  sqrt(mean((predict(model, tst_data) - tst_data$total_UPDRS) ^ 2))
}

calc_mae = function(model, tst_data){
  mean(abs(predict(model, tst_data) - tst_data$total_UPDRS))
}

get_bp = function(model) {
  unname(bptest(model)$p.value)
}

get_sw = function(model) {
  unname(shapiro.test(resid(model))$p.value)
}

get_num_params = function(model) {
  length(coef(model))
}

get_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

get_adj_r2 = function(model) {
  summary(model)$adj.r.squared
}

eval_model = function(model, tst_data){
  list(b_pagan = get_bp(model),
       shap_wilk = get_sw(model),
       rmse_loocv = get_loocv_rmse(model),
       rmse_trn = sqrt(mean(model$residuals^2)),
       rmse_tst = calc_rmse(model, tst_data),
       adj_r2 = get_adj_r2(model),
       num_p = get_num_params(model),
       mae_tst = calc_mae(model, tst_data))
}

diagnostic_plots = function(model, pcol="grey", lcol="dodgerblue"){
  par(mfrow = c(1,2))
  plot(fitted(model), resid(model), col = pcol, 
       xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residuals")
  abline(h=0, col = lcol)
  qqnorm(resid(model), col = pcol, main = "Normal Q-Q plot")
  qqline(resid(model), col = lcol)
}

non_influential_filter = function(model){
  cooks.distance(model) <= (4 / length(cooks.distance(model)))
}

plot_pva = function(predicted, actual){
  plot(actual, predicted, 
     col = "darkgrey",
     xlab = "Actual",
     ylab = "Predicted",
     main = "Predicted vs Actual")
  grid()
  abline(0, 1, col = "dodgerblue")
}
```


So, anyway, here's a simulation...
```{r}
set.seed(420)
num_sims = 5
num_metrics = 8

additive_evals = rep(list(rep(0, num_sims)), num_metrics)
interaction_evals = rep(list(rep(0, num_sims)), num_metrics)
additive_vif_evals = rep(list(rep(0, num_sims)), num_metrics)
interaction_vif_evals = rep(list(rep(0, num_sims)), num_metrics)
ob_fit_evals = rep(list(rep(0, num_sims)), num_metrics)
back_aic_evals = rep(list(rep(0, num_sims)), num_metrics)
back_bic_evals = rep(list(rep(0, num_sims)), num_metrics)

for (i in 1:num_sims) {
  # create a new train/test split
  park_trn_idx  = sample(nrow(parkins), size = trunc(0.80 * nrow(parkins)))
  park_trn_data = parkins[park_trn_idx, ]
  park_tst_data = parkins[-park_trn_idx, ]
  
  # train full additive model
  add_fit = lm(total_UPDRS ~ . , data = park_trn_data)
  add_eval = eval_model(add_fit, park_tst_data)
  
  # train full interaction model
  int_fit = lm(total_UPDRS ~ .^2 , data = park_trn_data)
  int_eval = eval_model(int_fit, park_tst_data)
  
  # use VIF to remove colinear columns
  vif_rem_park_trn_data = fix_vif(park_trn_data)
  
  # train additive model with columns removed by VIF
  add_vif_fit = lm(total_UPDRS ~ . , data = vif_rem_park_trn_data)
  add_vif_eval = eval_model(add_vif_fit, park_tst_data)
  
  # train interaction model with columns removed by VIF
  int_vif_fit = lm(total_UPDRS ~ .^2 , data = vif_rem_park_trn_data)
  int_vif_eval = eval_model(int_vif_fit, park_tst_data)
  
  
  # OB best model
  ob_init_fit = lm(total_UPDRS ~ ( . - `Jitter(%)` - `Jitter:RAP` - `Shimmer:APQ3`) ^ 2, data = park_trn_data)
  ob_fit = lm(total_UPDRS ~ ( . - `Jitter(%)` - `Jitter:RAP` - `Shimmer:APQ3`) ^ 2, data = park_trn_data, 
              subset = non_influential_filter(ob_init_fit))
  ob_eval = eval_model(ob_fit, park_tst_data)
  
  # Removing Influential Points, Interaction model, and step back AIC
  back_aic_fit = step(lm(total_UPDRS ~ .^2 , data = vif_rem_park_trn_data, 
                         subset = non_influential_filter(int_vif_fit)), direction = 'backward', trace = 0)
  back_aic_eval = eval_model(back_aic_fit, park_tst_data)
  
  # Removing Influential Points, Interaction model, and step back BIC
  n = length(resid(int_vif_fit))
  back_bic_fit = step(lm(total_UPDRS ~ .^2 , data = vif_rem_park_trn_data, 
                         subset = non_influential_filter(int_vif_fit)), direction = 'backward', 
                      trace = 0, k = log(n))
  back_bic_eval = eval_model(back_bic_fit, park_tst_data)
  
  for (j in 1:num_metrics) {
    additive_evals[[j]][i] = add_eval[j]
    interaction_evals[[j]][i] = int_eval[j]
    additive_vif_evals[[j]][i] = add_vif_eval[j]
    interaction_vif_evals[[j]][i] = int_vif_eval[j]
    ob_fit_evals[[j]][i] = ob_eval[j]
    back_aic_evals[[j]][i] = back_aic_eval[j]
    back_bic_evals[[j]][i] = back_bic_eval[j]
  }
  
}

```




Interaction Models

QQplots

Leverage and Influential Points

Colinearity





Model evaluation metrics



```{r, echo = FALSE, message = FALSE, warning = FALSE, eval=FALSE}



#1 Model best model: two interaction model and not influential point 
new_model = lm(total_UPDRS ~ (age + sex + test_time + `Jitter(Abs)` + 
    `Jitter:PPQ5` + `Jitter:DDP` + Shimmer + `Shimmer(dB)` + 
    `Shimmer:APQ5` + `Shimmer:APQ11` + `Shimmer:DDA` + NHR + 
    HNR + RPDE + DFA + PPE) ^ 2, data = park_trn_data)
new_fix_model = lm( total_UPDRS ~ (age + sex + test_time + `Jitter(Abs)` + 
    `Jitter:PPQ5` + `Jitter:DDP` + Shimmer + `Shimmer(dB)` + 
    `Shimmer:APQ5` + `Shimmer:APQ11` + `Shimmer:DDA` + NHR + 
    HNR + RPDE + DFA + PPE) ^ 2, data = park_trn_data, subset = non_influential_filter(new_model))

#Model2 with no collinearity not influential point 
new_model1 = lm(total_UPDRS ~ age + sex + test_time + RPDE + DFA + PPE,data = park_trn_data)
new_fix_model2 = lm(total_UPDRS ~ age + sex + test_time + RPDE + DFA + PPE, data = park_trn_data, subset = non_influential_filter(new_model1))

```




### Results

#### Colinearity scatterplot matrix

```{r, eval=TRUE, echo = FALSE, fig.align = 'center', message = FALSE, warning = FALSE}
library(GGally)
ggpairs(columns = c(5, 4, 2, 3, 1), data=parkins_orig)
ggpairs(columns = c(5, 17, 18, 19, 20, 21), data=parkins_orig)
ggpairs(columns = c(5, 6, 7, 8, 9, 10), data=parkins_orig)
ggpairs(columns = c(5, 11, 12, 13, 14, 15, 16), data=parkins_orig)
```

#### Table of best models, with metrics averaged over 5 data splits

```{r echo = FALSE, fig.align = 'center'}

dframe = data.frame(
  model = c("additive_full", "additive_vif", "interaction", "interaction_vif", "ob_best_model", "back_aic_interaction", "back_bic_interaction"),
  
  b_pagan = round(c(mean(unlist(additive_evals[1])), mean(unlist(additive_vif_evals[1])), mean(unlist(interaction_evals[1])), mean(unlist(interaction_vif_evals[1])), mean(unlist(ob_fit_evals[1])), mean(unlist(back_aic_evals[1])), mean(unlist(back_bic_evals[1]))), 3),
  
  shap_wilk = round(c(mean(unlist(additive_evals[2])), mean(unlist(additive_vif_evals[2])), mean(unlist(interaction_evals[2])), mean(unlist(interaction_vif_evals[2])), mean(unlist(ob_fit_evals[2])), mean(unlist(back_aic_evals[2])), mean(unlist(back_bic_evals[2]))), 3),
  
  rmse_loocv = round(c(mean(unlist(additive_evals[3])), mean(unlist(additive_vif_evals[3])), mean(unlist(interaction_evals[3])), mean(unlist(interaction_vif_evals[3])), mean(unlist(ob_fit_evals[3])), mean(unlist(back_aic_evals[3])), mean(unlist(back_bic_evals[3]))), 3),
  
  rmse_trn = round(c(mean(unlist(additive_evals[4])), mean(unlist(additive_vif_evals[4])), mean(unlist(interaction_evals[4])), mean(unlist(interaction_vif_evals[4])), mean(unlist(ob_fit_evals[4])), mean(unlist(back_aic_evals[4])), mean(unlist(back_bic_evals[4]))), 3),
  
  rmse_tst = round(c(mean(unlist(additive_evals[5])), mean(unlist(additive_vif_evals[5])), mean(unlist(interaction_evals[5])), mean(unlist(interaction_vif_evals[5])), mean(unlist(ob_fit_evals[5])), mean(unlist(back_aic_evals[5])), mean(unlist(back_bic_evals[5]))), 3),
  
  mae_tst = round(c(mean(unlist(additive_evals[8])), mean(unlist(additive_vif_evals[8])), mean(unlist(interaction_evals[8])), mean(unlist(interaction_vif_evals[8])), mean(unlist(ob_fit_evals[8])), mean(unlist(back_aic_evals[8])), mean(unlist(back_bic_evals[8]))), 3),
  
  adj_r2 = round(c(mean(unlist(additive_evals[6])), mean(unlist(additive_vif_evals[6])), mean(unlist(interaction_evals[6])), mean(unlist(interaction_vif_evals[6])), mean(unlist(ob_fit_evals[6])), mean(unlist(back_aic_evals[6])), mean(unlist(back_bic_evals[6]))), 3),
  
  num_pred = round(c(mean(unlist(additive_evals[7])), mean(unlist(additive_vif_evals[7])), mean(unlist(interaction_evals[7])), mean(unlist(interaction_vif_evals[7])), mean(unlist(ob_fit_evals[7])), mean(unlist(back_aic_evals[7])), mean(unlist(back_bic_evals[7]))), 1)
)

knitr::kable(dframe)
```

#### QQ Plots and Fitted vs Residuals
```{r, echo=FALSE, fig.align='center'}
park_trn_idx  = sample(nrow(parkins), size = trunc(0.80 * nrow(parkins)))
park_trn_data = parkins[park_trn_idx, ]
park_tst_data = parkins[-park_trn_idx, ]

vif_rem_park_trn_data = fix_vif(park_trn_data)
int_vif_fit = lm(total_UPDRS ~ .^2 , data = vif_rem_park_trn_data)
  int_vif_eval = eval_model(int_vif_fit, park_tst_data)

back_aic_fit = step(lm(total_UPDRS ~ .^2 , data = vif_rem_park_trn_data, 
                         subset = non_influential_filter(int_vif_fit)), direction = 'backward', trace = 0)

diagnostic_plots(back_aic_fit)
```

#### Predicted vs Actual plot
```{r, echo=FALSE, fig.align='center'}
plot_pva(predict(back_aic_fit, park_tst_data), park_tst_data$total_UPDRS)
```





### Discussion

Colinearity among columns

Influential points

overfitting

Why we chose the metrics we did

(Comparison with model from paper)



